{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing COVID-19 Data at the State and County Levels in Python\n",
    "\n",
    "## Part III: Building Maps in _geopandas_\n",
    "\n",
    "Now that we have downloaded the COVID-19 data and normalized cases and deaths by population, we can generate maps that allow us to compare values between counties. Just as with the visualizations from the last post,  were we to simply plot the total number of cases or deaths by county, the results would be biased as counties with larger populations would likely have more cases and more deaths. Unlike in the previous post, we will not compare counties by using a common anchor to compare spread (i.e., days since cases per million or deaths per million exceeded some value). Instead, we will see how the spread developed across the country, starting in the northeast, eventually making its way to other regions.\n",
    "\n",
    "Make sure that you have completed the [previous lesson](https://github.com/jlcatonjr/Learn-Python-for-Stats-and-Econ/blob/master/Projects/COVID19/Visualizing%20COVID-19%20Data%20at%20the%20State%20and%20County%20Levels%20in%20Python%20-%20Parts%20I%20%26%20II.ipynb) before you continue. You will need to download the appropriat shape file - available in this github repository or at the U.S. Census [website](https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html). If you'd like, you can continue building from the previous script. I've included only what is necessary, having dropped the dataframe that aggregated county data at the state level. I have also removed the *zero_day_dict*, since we will not be comparing the state of the spread in light of a common anchor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createCOVID19StateAndCountyVisualization.py\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# We won't actually use datetime directly. Since the dataframe index will use \n",
    "# data formatted as datetime64, I import it in case I need to use the datetime\n",
    "# module to troubleshoot later \n",
    "import datetime\n",
    "# you could technically call many of the submodules from matplotlib using mpl., \n",
    "#but for convenience we explicitly import submodules. These will be used for \n",
    "# constructing visualizations\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.ticker as mtick\n",
    "import datadotworld as dw\n",
    "\n",
    "\n",
    "def import_geo_data(filename, index_col = \"Date\", FIPS_name = \"FIPS\"):\n",
    "    # import county level shapefile\n",
    "    map_data = geopandas.read_file(filename = filename,                                   \n",
    "                                   index_col = index_col)\n",
    "    # rename fips code to match variable name in COVID-19 data\n",
    "    map_data.rename(columns={\"State\":\"state\"},\n",
    "                    inplace = True)\n",
    "    # Combine statefips and county fips to create a single fips value\n",
    "    # that identifies each particular county without referencing the \n",
    "    # state separately\n",
    "    map_data[FIPS_name] = map_data[\"STATEFP\"].astype(str) + \\\n",
    "        map_data[\"COUNTYFP\"].astype(str)\n",
    "    map_data[FIPS_name] = map_data[FIPS_name].astype(np.int64)\n",
    "    # set FIPS as index\n",
    "    map_data.set_index(FIPS_name, inplace=True)\n",
    "    \n",
    "    return map_data\n",
    "\n",
    "def import_covid_data(filename, FIPS_name):\n",
    "    # Load COVID19 county data using datadotworld API\n",
    "    # Data provided by Johns Hopkins, file provided by Associated Press\n",
    "    dataset = dw.load_dataset(\"associatedpress/johns-hopkins-coronavirus-case-tracker\",\n",
    "                              auto_update = True)\n",
    "    # the dataset includes multiple dataframes. We will only use #2\n",
    "    covid_data = dataset.dataframes[\"2_cases_and_deaths_by_county_timeseries\"]\n",
    "    # Include only oberservation for political entities within states\n",
    "    # i.e., not territories, etc... drop any nan fip values with covid_data[FIPS_name] > 0\n",
    "    covid_data = covid_data[covid_data[FIPS_name] < 57000]\n",
    "    covid_data = covid_data[covid_data[FIPS_name] > 0]\n",
    "\n",
    "    # Transform FIPS codes into integers (not floats)\n",
    "    covid_data[FIPS_name] = covid_data[FIPS_name].astype(int)\n",
    "    covid_data['date'] = pd.to_datetime(covid_data['date'])\n",
    "    covid_data.set_index([\"date\", FIPS_name], inplace = True)\n",
    "    # Prepare a column for state abbreviations. We will draw these from a\n",
    "    # dictionary created in the next step.\n",
    "    covid_data[\"state_abr\"] = \"\"\n",
    "    for state, abr in state_dict.items():\n",
    "        covid_data.loc[covid_data[\"state\"] == state, \"state_abr\"] = abr\n",
    "    # Create \"Location\" which concatenates county name and state abbreviation \n",
    "    covid_data[\"Location\"] = covid_data[\"location_name\"] + \", \" + \\\n",
    "        covid_data[\"state_abr\"]\n",
    "\n",
    "    return covid_data\n",
    "\n",
    "def create_covid_geo_dataframe(covid_data, map_data, dates):\n",
    "    # create geopandas dataframe with multiindex for date\n",
    "    # original geopandas dataframe had no dates, so copies of the df are \n",
    "    # stacked vertically, with a new copy for each date in the covid_data index\n",
    "    #(dates is a global)\n",
    "    i = 0\n",
    "    counties = covid_data.groupby(\"fips_code\").mean().index\n",
    "    for date in dates:\n",
    "        # select county observations from each date in dates\n",
    "        df = covid_data[covid_data.index.get_level_values(\"date\")==date]\n",
    "        # use the fips_codes from the slice of covid_data to select counties\n",
    "        # from the map_data index,making sure that the map_data index matches\n",
    "        # the covid_data index\n",
    "        agg_df = map_data.loc[counties]\n",
    "        # each row for agg_df will reflect that \n",
    "        agg_df[\"date\"] = date\n",
    "        if i == 0:\n",
    "            # create the geodataframe, select coordinate system (.crs) to\n",
    "            # match map_data.crs\n",
    "            matching_gpd = geopandas.GeoDataFrame(agg_df, crs = map_data.crs)\n",
    "            i += 1\n",
    "        else:\n",
    "            # after initial geodataframe is created, stack a dataframe for\n",
    "            # each date in dates. Once completed, index of matching_gpd\n",
    "            # will match index of covid_data\n",
    "            matching_gpd = matching_gpd.append(agg_df, ignore_index = False)         \n",
    "    # Set mathcing_gpd index as[\"fips_code\", \"date\"], liked covid_data index\n",
    "    matching_gpd.reset_index(inplace=True)\n",
    "    matching_gpd.set_index([\"date\", \"fips_code\"], inplace = True)\n",
    "    # add each column from covid_data to mathcing_gpd\n",
    "    for key, val in covid_data.items():\n",
    "        matching_gpd[key] = val\n",
    "\n",
    "    return matching_gpd       \n",
    "\n",
    "def create_new_vars(covid_data, moving_average_days):\n",
    "    # use a for loop that performs the same operations on data for cases and for deaths\n",
    "    for key in [\"cases\", \"deaths\"]:\n",
    "        # create a version of the key with the first letter capitalized\n",
    "        cap_key = key.title()\n",
    "        covid_data.rename(columns={\"cumulative_\" + key :\"Total \" + cap_key}, \n",
    "                  inplace = True)\n",
    "        covid_data[cap_key + \" per Million\"] = covid_data[\"Total \" + cap_key].fillna(0)\\\n",
    "            .div(covid_data[\"total_population\"]).mul(10 ** 6)\n",
    "        # generate daily data normalized per million population by taking the daily difference within each\n",
    "        # entity (covid_data.index.names[0]), dividing this value by population and multiplying that value\n",
    "        # by 1 million 10 ** 6\n",
    "        covid_data[\"Daily \" + cap_key] = covid_data[\"Total \" + cap_key ].groupby(covid_data.index.names[1])\\\n",
    "            .diff(1)\n",
    "        covid_data[\"Daily \" + cap_key + \" \" + str(moving_average_days) + \" Day MA\"] = covid_data[\n",
    "            \"Daily \" + cap_key].rolling(moving_average_days).mean()           \n",
    "                                   \n",
    "        # taking the rolling average; choice of number of days is passed as moving_average_days\n",
    "        covid_data[\"Daily \" + cap_key + \" per Million \" + str(moving_average_days) + \" Day MA\"] = \\\n",
    "            covid_data[\"Daily \" + cap_key + \" \" + str(moving_average_days) + \" Day MA\"]\\\n",
    "            .div(covid_data[\"total_population\"]).mul(10 ** 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\datadotworld\\models\\dataset.py:209: UserWarning: Unable to set data frame dtypes automatically using 2_cases_and_deaths_by_county_timeseries schema. Data types may need to be adjusted manually. Error: Integer column has NA values in column 2\n",
      "  'Error: {}'.format(resource_name, e))\n"
     ]
    }
   ],
   "source": [
    "# I include this dictionary to convenienlty cross reference state names and\n",
    "# state abbreviations.\n",
    "state_dict = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', \n",
    "    'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL', \n",
    "    'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL',\n",
    "    'Indiana': 'IN', 'Iowa': 'IA','Kansas': 'KS', 'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO',\n",
    "    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX',\n",
    "    'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA',\n",
    "    'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'}\n",
    "\n",
    "plt.rcParams['axes.ymargin'] = 0\n",
    "plt.rcParams['axes.xmargin'] = 0\n",
    "plt.rcParams.update({'font.size': 32})\n",
    "\n",
    "#if \"data_processed\" not in locals():\n",
    "fips_name = \"fips_code\"\n",
    "covid_filename = \"COVID19DataAP.csv\"\n",
    "# rename_FIPS matches map_data FIPS with COVID19 FIPS name\n",
    "map_data = import_geo_data(filename = \"countiesWithStatesAndPopulation.shp\",\n",
    "                index_col = \"Date\", FIPS_name= fips_name)\n",
    "covid_data = import_covid_data(filename = covid_filename, FIPS_name = fips_name)\n",
    "# dates will be used to create a geopandas DataFrame with multiindex \n",
    "dates = sorted(list(set(covid_data.index.get_level_values(\"date\"))))\n",
    "covid_data = create_covid_geo_dataframe(covid_data, map_data, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_days = 7\n",
    "create_new_vars(covid_data, moving_average_days)\n",
    "start_date = \"03-15-2020\"     \n",
    "end_date = dates[-1]\n",
    "# once data is processed, it is saved in the memory\n",
    "# the if statement at the top of this block of code instructs the computer\n",
    "# not to repeat these operations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a map showing the state of the spread at the latest date. The process for this is simple. We call data whose index is the latest date and use the _.plot()_ method from the _geopandas_ dataframe. The tricky part will be to use a for loop to plot different kinds of data - levels and rates - since each of these categories will required different features.\n",
    "\n",
    "To start, we need to select data from counties  within the 48 states, otherwise Alaska and Hawaii will be included, making the representation of the 48 states much smaller. The measures that are slected are rough estimates, but all that matters is that the 48 states reside within the boundaries chosen. Similar to the *data_processed* variable, I include a *map_bounded* variable so that this computation will not be repeated when the script is run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_within_bounds(data, minx, miny, maxx, maxy):\n",
    "    data = data[data.bounds[\"maxx\"] <= maxx]\n",
    "    data = data[data.bounds[\"maxy\"] <= maxy]\n",
    "    data = data[data.bounds[\"minx\"] >= minx]\n",
    "    data = data[data.bounds[\"miny\"] >= miny]\n",
    "    \n",
    "    return data\n",
    "\n",
    "date = dates[-1]\n",
    "\n",
    "if \"map_bounded\" not in locals():\n",
    "    minx = covid_data.loc[date].bounds[\"minx\"].min()\n",
    "    miny = covid_data.loc[date].bounds[\"miny\"].min()\n",
    "    maxx = -58\n",
    "    maxy = covid_data.loc[date].bounds[\"maxy\"].max()\n",
    "    # find counties using only 1 date, only performs operation once instead of \n",
    "    # several hundred times\n",
    "    bounded_data =  select_data_within_bounds(covid_data.loc[date], minx, miny, maxx, maxy)\n",
    "    counties = bounded_data.groupby(\"fips_code\").mean().index\n",
    "    covid_map_data =covid_data[covid_data.index.get_level_values(\"fips_code\").isin(counties)]\n",
    "    map_bounded = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's test out the plot function for _geopandas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "covid_map_data.fillna(0, inplace = True)\n",
    "covid_map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "plt.rcParams.update({\"font.size\": 30})\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "key = \"Deaths per Million\"\n",
    "df = covid_map_data.loc[date]\n",
    "df.plot(ax=ax, cax = ax, column=key, linewidth=.5, \n",
    "             edgecolor='lightgrey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result looks okay. A few things can be improved. First, it's usually a good idea to select a colormap that spans a narrow range of colors. For this purpose, we will choose to use the colorbar defined by \"Reds\" in matplotlib. Color choice also conveys affect to the reader. A choice of color, say \"Blues\", might  strike the viewer as conveying neutral content. Our choice of red conveys that areas that are darker shades of red tend to have been more greatly impacted by the COVID-19. The variable _\"Deaths per Million\"_ normalizes death by population, allowing for a fair comparison between counties. \n",
    "\n",
    "Since we are plotting levels of values, it will be useful to compare logged values. This will give us a sense that some areas are doing better or worse by orders of magnitude, depending on the plot, about 10 to 20 times better or worse given each change in color. To have colors represent a range of logged values, we use the _cm.colors.LogNorm()_ and apply this with _plt.cm.ScalarMappable()_. We explicitly identify min and max values as this will be useful to us when we plot animations over time later in this lesson.\n",
    "\n",
    "Finally, in the title, we identify the date, region, and the category of data represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid.inset_locator import inset_axes\n",
    "fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "plt.rcParams.update({\"font.size\": 30})\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "key = \"Deaths per Million\"\n",
    "df = covid_map_data[~covid_map_data[\"state\"].str.contains(\"Alaska|Hawaii\")].loc[date]\n",
    "cmap = cm.get_cmap('Reds', 10)\n",
    "vmin = 1 \n",
    "vmax = df[key].max()\n",
    "norm = cm.colors.LogNorm(vmin=vmin, vmax =vmax)\n",
    "plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "df.plot(ax=ax, cax = ax, column=key, vmin=vmin ,vmax = vmax, \n",
    "             cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "             norm = norm)\n",
    "ax.set_title(str(date)[:10] + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)\n",
    "axins = {}\n",
    "axins[\"Alaska\"] = inset_axes(ax, width=\"17%\", height=\"35%\", loc=\"lower left\")\n",
    "axins[\"Hawaii\"] = inset_axes(ax, width=\"50%\", height=\"40%\", loc=\"lower left\")\n",
    "for state in axins.keys():\n",
    "    axins[state].set_xticks([])\n",
    "    axins[state].set_yticks([])\n",
    "    axins[state].axis(\"off\")\n",
    "    covid_map_data[covid_map_data[\"state\"].str.contains(state)].loc[date].plot(\n",
    "        ax = axins[state],cax = ax, cmap = cmap, norm = norm)\n",
    "axins[\"Hawaii\"].set_xlim(-161, -154)\n",
    "axins[\"Alaska\"].set_ylim(53, 71)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to include a colorbar so that the viewer knows what values are conveyed by map colors. This requires the addition of several parameters that allow for inclusion of a colorbar legend. To construct the colorbar, we need to call *make_axes_locatable(ax)*, then use this to create a colorbar axis, _cax_. Using _cax_ and *cmap*, created in the block of code executed in the previous section, we are able to create a colorbar. To control the value format, we create a list of the axis values, making sure that they are integers (not floats). Then, identify the newly created _matplotlib_ objects in the _.plot()_ method.\n",
    "\n",
    "Since the color axis is logged, technically it doesn't include a representation for *0*. When passing the dataframe, replace all 0 values with 1 in order to transform the white counties into beige. If you were to use this map, be sure to note that you have made this adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "plt.rcParams.update({\"font.size\": 30})\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "key = \"Deaths per Million\"\n",
    "# this time we replace 0 values with 1\n",
    "# so that these values show up as beige instead of as white\n",
    "# when color axis is logged\n",
    "df = covid_map_data[~covid_map_data[\"state\"].str.contains(\"Alaska|Hawaii\")].loc[date]\n",
    "# set range of colorbar\n",
    "vmin = 1 \n",
    "vmax = df[key].max()\n",
    "# choose colormap\n",
    "cmap = cm.get_cmap('Reds', 10)\n",
    "# format colormap\n",
    "norm = cm.colors.LogNorm(vmin = vmin, vmax = vmax)\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "# empty array for the data range\n",
    "sm._A = []\n",
    "# prepare space for colorbar\n",
    "divider = make_axes_locatable(ax)\n",
    "size = \"5%\" \n",
    "cax = divider.append_axes(\"right\", size = size, pad = 0.1)\n",
    "# add colorbar to figure\n",
    "cbar = fig.colorbar(sm, cax=cax, cmap = cmap)\n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "vals = list(cbar.ax.get_yticks())\n",
    "vals.append(vmax)\n",
    "# format colorbar values as int\n",
    "cbar.ax.set_yticklabels([int(x) for x in vals])\n",
    "cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "\n",
    "\n",
    "df.plot(ax=ax, cax = cax, column=key, vmin=vmin ,vmax = vmax, \n",
    "             cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "             norm = norm)\n",
    "ax.set_title(str(date)[:10] + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)\n",
    "axins = {}\n",
    "axins[\"Alaska\"] = inset_axes(ax, width=\"17%\", height=\"33%\", loc=\"lower left\")\n",
    "axins[\"Hawaii\"] = inset_axes(ax, width=\"50%\", height=\"40%\", loc=\"lower left\")\n",
    "for state in axins.keys():\n",
    "    axins[state].set_xticks([])\n",
    "    axins[state].set_yticks([])\n",
    "    axins[state].axis(\"off\")\n",
    "    covid_map_data[covid_map_data[\"state\"].str.contains(state)].loc[date].plot(\n",
    "        ax = axins[state],cax = ax, cmap = cmap, norm = norm)\n",
    "axins[\"Hawaii\"].set_xlim(-161, -154)\n",
    "axins[\"Alaska\"].set_ylim(53, 71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've made a quality map. Next, let's use a for loop to create maps for all for categories that we plotted in the previous post. This is simple. First we define a list of keys, and iterate over each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"Cases per Million\", \"Deaths per Million\", \n",
    "        \"Daily Cases per Million 7 Day MA\", \"Daily Deaths per Million 7 Day MA\"]\n",
    "for key in keys:\n",
    "    fig, ax = plt.subplots(figsize=(18,8),\n",
    "            subplot_kw = {'aspect': 'equal'})   \n",
    "    plt.rcParams.update({\"font.size\": 30})\n",
    "    plt.xticks(fontsize = 25)\n",
    "    plt.yticks(fontsize = 25)\n",
    "    # this time we replace 0 values with 1\n",
    "    # so that these values show up as beige instead of as white\n",
    "    # when color axis is logged\n",
    "    df = covid_map_data[~covid_map_data[\"state\"].str.contains(\"Alaska|Hawaii\")].loc[date]\n",
    "    vmin = 1 \n",
    "    vmax = df[key].max()\n",
    "\n",
    "    cmap = cm.get_cmap('Reds', 10)\n",
    "    # only log level values\n",
    "    if \"Daily\" not in key:\n",
    "        norm = cm.colors.LogNorm(vmin=vmin, vmax =vmax)\n",
    "    # if daily rate, do not log values\n",
    "    else:\n",
    "        norm = cm.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "    # add the colorbar to the figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    size = \"5%\" \n",
    "    # prepare space for the color bar\n",
    "    cax = divider.append_axes(\"right\", size = size, pad = 0.1)\n",
    "    # add colorbar to figure\n",
    "    cbar = fig.colorbar(sm, cax=cax, cmap = cmap)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    vals = list(cbar.ax.get_yticks())\n",
    "    vals.append(vmax)\n",
    "    \n",
    "    # format colorbar values as int\n",
    "    cbar.ax.set_yticklabels([int(x) for x in vals])\n",
    "    cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "\n",
    "    df.plot(ax=ax, cax = cax, column=key, vmin=vmin ,vmax = vmax, \n",
    "                 cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "                 norm = norm)\n",
    "    ax.set_title(str(date)[:10] + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)\n",
    "    axins = {}\n",
    "    axins[\"Alaska\"] = inset_axes(ax, width=\"17%\", height=\"35%\", loc=\"lower left\")\n",
    "    axins[\"Hawaii\"] = inset_axes(ax, width=\"50%\", height=\"40%\", loc=\"lower left\")\n",
    "    for state in axins.keys():\n",
    "        axins[state].set_xticks([])\n",
    "        axins[state].set_yticks([])\n",
    "        axins[state].axis(\"off\")\n",
    "        covid_map_data[covid_map_data[\"state\"].str.contains(state)].loc[date].plot(\n",
    "            ax = axins[state],cax = ax, cmap = cmap, norm = norm)\n",
    "    axins[\"Hawaii\"].set_xlim(-161, -154)\n",
    "    axins[\"Alaska\"].set_ylim(53, 71)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Animated Visualization\n",
    "\n",
    "Now that you have built a map, it is only a few more steps to creating an animation and [saving as](https://towardsdatascience.com/animations-with-matplotlib-d96375c5442c) an mp4 (or gif or other format that you prefer) that shows how COVID-19 has evolved over time! \n",
    "\n",
    "We will be using the _FuncAnimation()_ method from _matplotlib_. This requires that we create to functions: *init()* and *plot_map()*. First we will build a static visualization using these functions, then we will use these functions in combination with _FuncAnimation()_ to create dynamic the evolution of the map over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_within_bounds(data, minx, miny, maxx, maxy):\n",
    "    data = data[data.bounds[\"maxx\"] <= maxx]\n",
    "    data = data[data.bounds[\"maxy\"] <= maxy]\n",
    "    data = data[data.bounds[\"minx\"] >= minx]\n",
    "    data = data[data.bounds[\"miny\"] >= miny]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def plot_map(*kwargs):\n",
    "    plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    plot_df = df[df.index.get_level_values(\"date\")==date]\n",
    "    plot_df.plot(ax=ax, cax = ax, column=key, vmin=vmin ,vmax = vmax, \n",
    "                 cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "                 norm = norm)\n",
    "    ax.set_title(str(date)[:10] + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)\n",
    "    \n",
    "def init(*kwargs):\n",
    "    size = \"5%\"     \n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "    # add the colorbar to the figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size = size, pad = 0.1)\n",
    "    # add colorbar to figure\n",
    "    cbar = fig.colorbar(sm, cax=cax, cmap = cmap)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    vals = list(cbar.ax.get_yticks())\n",
    "    vals.append(vmax)\n",
    "    if \"Daily\" not in key: vals[0] = 0 \n",
    "    # format colorbar with logged or observed values\n",
    "    if log:\n",
    "        cbar.ax.yaxis.set_major_formatter(mtick.LogFormatter())\n",
    "    else:\n",
    "        cbar.ax.yaxis.set_major_formatter(mtick.Formatter())\n",
    "    # format colorbar values as int\n",
    "    cbar.ax.set_yticklabels([int(x) for x in vals])\n",
    "    cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "    \n",
    "date = dates[-1]\n",
    "keys = [\"Cases per Million\", \"Deaths per Million\", \n",
    "        \"Daily Cases per Million 7 Day MA\", \"Daily Deaths per Million 7 Day MA\"]\n",
    "\n",
    "#if \"map_bounded\" not in locals():\n",
    "#    minx = -127\n",
    "#    miny = 23\n",
    "#    maxx = -58\n",
    "#    maxy = 54\n",
    "#    covid_map_data = select_data_within_bounds(covid_data, minx, miny, maxx, maxy)\n",
    "#    map_bounded = True\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "    # log = False if \"Daily\" in key else True\n",
    "    log = False\n",
    "    # this time we replace 0 values with 1\n",
    "    # so that these values show up as beige  instead of as white\n",
    "    # when color axis is logged\n",
    "    df = covid_map_data.replace(0,1)\n",
    "    vmin= 1\n",
    "    vmax = df[key][df.index.get_level_values(\"date\") == date].max()\n",
    "    # Create colorbar as a legend\n",
    "    cmap = cm.get_cmap('Reds', 10)\n",
    "    if log:\n",
    "        norm = cm.colors.LogNorm(vmin=vmin, vmax =vmax)\n",
    "    else:\n",
    "        norm = cm.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "    plt.rcParams.update({\"font.size\": 30})\n",
    "    plt.xticks(fontsize = 25)\n",
    "    plt.yticks(fontsize = 25)\n",
    "    # the functions will unpack the tuple. The same names variable names\n",
    "    # are used in the function\n",
    "    kwargs = (df, key, log, date, fig, ax, cmap, norm, vmin, vmax)\n",
    "    init(kwargs)\n",
    "    plot_map(kwargs)\n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to use FuncAnimation to show the evolution of the virus over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . . \n",
    "# list dates starting in mid-march\n",
    "dates = sorted(list(set(covid_data.index.get_level_values(\"date\"))))\n",
    "dates = dates[(len(dates) - 55) * -1 - 1   ::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(date, *kwargs):\n",
    "    # For each frame, clear old content\n",
    "    ax.clear()\n",
    "    # the FuncAnimation cycles from 0 to i frames,\n",
    "    # use the i value for your dates\n",
    "    plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    plot_df = df[df.index.get_level_values(\"date\")==date]\n",
    "    plot_df[~plot_df[\"state\"].str.contains(\n",
    "                    \"Alaska|Hawaii\")].plot(ax=ax, cax = ax, column=key,\n",
    "                 cmap = cmap, legend=False, linewidth=.5, edgecolor='lightgrey', \n",
    "                 norm = norm)\n",
    "\n",
    "    axins = {}\n",
    "    axins[\"Alaska\"] = inset_axes(ax, width=\"17%\", height=\"35%\", loc=\"lower left\")\n",
    "    axins[\"Hawaii\"] = inset_axes(ax, width=\"50%\", height=\"40%\", loc=\"lower left\")\n",
    "    for state, axin in axins.items():\n",
    "        axins[state].set_xticks([])\n",
    "        axins[state].set_yticks([])\n",
    "        axins[state].axis(\"off\")\n",
    "        plot_df[plot_df[\"state\"].str.contains(state)].plot(ax=axins[state], cax = ax, column=key, \n",
    "                                                       cmap = cmap, legend=False, \n",
    "                                                       linewidth=.5, edgecolor='lightgrey', \n",
    "                                                       norm = norm)\n",
    "    axins[\"Hawaii\"].set_xlim(-161, -154)\n",
    "    axins[\"Alaska\"].set_ylim(53, 71)\n",
    "\n",
    "    ax.set_title(str(date)[:10] + \"\\n\" + \"COVID-19 in the U.S.\", fontsize = 30)\n",
    "    \n",
    "def init(*kwargs):\n",
    "    size = \"5%\" \n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "    # make space for colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size = size, pad = 0.1)\n",
    "    # add colorbar to figure\n",
    "    cbar = fig.colorbar(sm, cax=cax, cmap = cmap)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    vals = list(cbar.ax.get_yticks())\n",
    "    vals.append(vmax)\n",
    "    #if \"Daily\" not in key: \n",
    "    vals[0] = 0\n",
    "    # format display of values on colorbar\n",
    "    if log:\n",
    "        cbar.ax.yaxis.set_major_formatter(mtick.LogFormatter())\n",
    "    else:\n",
    "        cbar.ax.yaxis.set_major_formatter(mtick.Formatter())\n",
    "    # format colorbar values as int\n",
    "    cbar.ax.set_yticklabels([int(x) for x in vals])\n",
    "    cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "    \n",
    "keys = [ \"Deaths per Million\", \"Daily Cases per Million 7 Day MA\", \"Daily Deaths per Million 7 Day MA\"]\n",
    "\n",
    "print(dates)\n",
    "# create dictionary to hold animations. We will call these in the next cell.\n",
    "anim_dict = {}\n",
    "for key in keys:\n",
    "    log = False #if \"Daily\" in key else True\n",
    "    # this time we replace 0 values with 1\n",
    "    # so that these values show up as beige  instead of as white\n",
    "    # when color axis is logged\n",
    "    df = covid_map_data\n",
    "    vmin= 0\n",
    "    vmax = df[key].max()\n",
    "    # Create colorbar as a legend\n",
    "    cmap = cm.get_cmap('Reds', 10)\n",
    "    if log:\n",
    "        norm = cm.colors.LogNorm(vmin=vmin, vmax =vmax)\n",
    "    else:\n",
    "        norm = cm.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18,8),\n",
    "        subplot_kw = {'aspect': 'equal'})   \n",
    "    plt.rcParams.update({\"font.size\": 30})\n",
    "    plt.xticks(fontsize = 25)\n",
    "    plt.yticks(fontsize = 25)\n",
    "    # the functions will unpack the tuple. The same names variable names\n",
    "    # are used in the function\n",
    "    kwargs = (df, key, log, fig, ax, cmap, norm, vmin, vmax)\n",
    "    frames = dates\n",
    "    #anim = FuncAnimation(fig, plot_map, frames = dates, \n",
    "    #                    blit = False, init_func = init, interval=150, \n",
    "    #                     fargs = kwargs)\n",
    "    # Use the next line to save the video as an MP4.\n",
    "    #anim.save(key + \".mp4\", writer = \"ffmpeg\")\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the saved videos in the folder holding your python script. While Jupyter allows you to embed videos, Github's frame for loading Jupyter notebooks does not play videos. You can click the links to download the MP4 files for each frame.\n",
    "\n",
    "[Cases per Million](https://github.com/jlcatonjr/Learn-Python-for-Stats-and-Econ/raw/master/Projects/COVID19/Cases%20per%20Million.mp4)\n",
    "\n",
    "[Deaths per Million](https://github.com/jlcatonjr/Learn-Python-for-Stats-and-Econ/raw/master/Projects/COVID19/Deaths%20per%20Million.mp4)\n",
    "\n",
    "[Daily Cases per Million MA](https://github.com/jlcatonjr/Learn-Python-for-Stats-and-Econ/raw/master/Projects/COVID19/Daily%20Cases%20per%20Million%20MA.mp4)\n",
    "\n",
    "[Daily Deaths per Million MA](https://github.com/jlcatonjr/Learn-Python-for-Stats-and-Econ/raw/master/Projects/COVID19/Daily%20Deaths%20per%20Million%20MA.mp4)\n",
    "\n",
    "Great work! You have learned how to use _geopandas_ to build maps. Then you learned to use _funcAnimation()_ from _matplotlib_ to create videos. As you have seen, once you are able to build a single map, there is only a bit more work required to create an animation that shows the evolution of geospatial data over time.\n",
    "\n",
    "If you found this lesson useful, check out [Learn Python for Economic Computation](https://github.com/jlcatonjr/Learn-Python-for-Stats-and-Econ/tree/master/Textbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data= covid_map_data.copy()\n",
    "save_data= save_data[[\"Total Cases\", \"Total Deaths\",\n",
    "                      'Cases per Million', \"Deaths per Million\",\n",
    "                      \"Daily Cases\", \"Daily Deaths\",\n",
    "                      \"Daily Cases per Million 7 Day MA\", \"Daily Deaths per Million 7 Day MA\",\n",
    "                      \"total_population\", \"state\"]]\n",
    "\n",
    "save_data.to_parquet(\"../COVID19DataForVoila.parquet.gzip\", compression = \"gzip\",\n",
    "                    engine = \"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
